#!/usr/bin/env python3
"""
Utility functions for post-processing evaluation results.
This script provides helper functions to analyze and visualize the results
generated by the federated_model_evaluation.ipynb notebook.
"""

import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List, Tuple, Optional


class ResultsAnalyzer:
    """Analyze evaluation results from the notebook."""

    def __init__(self, results_csv: str = "evaluation_results.csv"):
        """
        Initialize analyzer with results CSV.

        Args:
            results_csv: Path to the evaluation_results.csv file
        """
        self.results_df = pd.read_csv(results_csv)
        self.summary_stats = None

    def compute_summary_statistics(self) -> pd.DataFrame:
        """Compute summary statistics across all dimensions."""
        summary = (
            self.results_df.groupby(["Partition", "Aggregator"])
            .agg(
                {
                    "mIoU": ["mean", "std", "min", "max"],
                    "F1_Score": ["mean", "std", "min", "max"],
                    "Accuracy": ["mean", "std"],
                }
            )
            .round(4)
        )

        self.summary_stats = summary
        return summary

    def get_convergence_trends(self, partition: int, aggregator: str) -> pd.DataFrame:
        """
        Get convergence trends for a specific partition and aggregator.

        Args:
            partition: Partition ID
            aggregator: Aggregator name (e.g., 'FedAvg')

        Returns:
            DataFrame with trends across communication rounds
        """
        df = self.results_df[
            (self.results_df["Partition"] == partition)
            & (self.results_df["Aggregator"] == aggregator)
        ]

        trends = (
            df.groupby("Communication_Round")
            .agg(
                {
                    "mIoU": ["mean", "std"],
                    "F1_Score": ["mean", "std"],
                    "Accuracy": "mean",
                }
            )
            .round(4)
        )

        return trends

    def compare_aggregators(self, partition: int) -> pd.DataFrame:
        """
        Compare performance across aggregators for a given partition.

        Args:
            partition: Partition ID

        Returns:
            DataFrame comparing aggregators
        """
        df = self.results_df[self.results_df["Partition"] == partition]

        comparison = (
            df.groupby("Aggregator")
            .agg(
                {
                    "mIoU": ["mean", "std", "max"],
                    "F1_Score": ["mean", "std", "max"],
                    "Accuracy": "mean",
                }
            )
            .round(4)
        )

        return comparison

    def get_client_performance(
        self, partition: int, aggregator: str, client: int
    ) -> pd.DataFrame:
        """
        Get detailed performance for a specific client.

        Args:
            partition: Partition ID
            aggregator: Aggregator name
            client: Client ID

        Returns:
            DataFrame with client performance across rounds
        """
        df = self.results_df[
            (self.results_df["Partition"] == partition)
            & (self.results_df["Aggregator"] == aggregator)
            & (self.results_df["Client"] == client)
        ]

        return df.sort_values("Communication_Round")

    def save_summary_to_latex(self, output_file: str = "summary_table.tex"):
        """Save summary statistics in LaTeX table format."""
        if self.summary_stats is None:
            self.compute_summary_statistics()

        latex_str = self.summary_stats.to_latex()
        with open(output_file, "w") as f:
            f.write(latex_str)

        print(f"LaTeX table saved to {output_file}")


def plot_convergence_curves(
    results_df: pd.DataFrame, partition: int, figsize: Tuple[int, int] = (14, 5)
):
    """
    Plot convergence curves for all aggregators in a partition.

    Args:
        results_df: Results DataFrame
        partition: Partition ID
        figsize: Figure size
    """
    df = results_df[results_df["Partition"] == partition]

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)

    # mIoU convergence
    for aggregator in df["Aggregator"].unique():
        agg_data = (
            df[df["Aggregator"] == aggregator]
            .groupby("Communication_Round")["mIoU"]
            .mean()
        )
        ax1.plot(
            agg_data.index, agg_data.values, marker="o", label=aggregator, linewidth=2
        )

    ax1.set_xlabel("Communication Round", fontsize=11)
    ax1.set_ylabel("mIoU", fontsize=11)
    ax1.set_title(
        f"mIoU Convergence - Partition {partition}", fontsize=12, fontweight="bold"
    )
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # F1-Score convergence
    for aggregator in df["Aggregator"].unique():
        agg_data = (
            df[df["Aggregator"] == aggregator]
            .groupby("Communication_Round")["F1_Score"]
            .mean()
        )
        ax2.plot(
            agg_data.index, agg_data.values, marker="s", label=aggregator, linewidth=2
        )

    ax2.set_xlabel("Communication Round", fontsize=11)
    ax2.set_ylabel("F1-Score", fontsize=11)
    ax2.set_title(
        f"F1-Score Convergence - Partition {partition}", fontsize=12, fontweight="bold"
    )
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    return fig


def plot_client_heterogeneity(
    results_df: pd.DataFrame,
    partition: int,
    aggregator: str,
    figsize: Tuple[int, int] = (12, 5),
):
    """
    Plot client heterogeneity - showing variation in performance across clients.

    Args:
        results_df: Results DataFrame
        partition: Partition ID
        aggregator: Aggregator name
        figsize: Figure size
    """
    df = results_df[
        (results_df["Partition"] == partition)
        & (results_df["Aggregator"] == aggregator)
    ]

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)

    # Client-wise mIoU variation
    client_miou = df.groupby("Client")["mIoU"].agg(["mean", "std"])
    ax1.bar(
        client_miou.index,
        client_miou["mean"],
        yerr=client_miou["std"],
        capsize=5,
        alpha=0.7,
    )
    ax1.set_xlabel("Client", fontsize=11)
    ax1.set_ylabel("mIoU", fontsize=11)
    ax1.set_title(
        f"Client mIoU Variation - {aggregator}", fontsize=12, fontweight="bold"
    )
    ax1.grid(axis="y", alpha=0.3)

    # Client-wise F1-Score variation
    client_f1 = df.groupby("Client")["F1_Score"].agg(["mean", "std"])
    ax2.bar(
        client_f1.index,
        client_f1["mean"],
        yerr=client_f1["std"],
        capsize=5,
        color="orange",
        alpha=0.7,
    )
    ax2.set_xlabel("Client", fontsize=11)
    ax2.set_ylabel("F1-Score", fontsize=11)
    ax2.set_title(
        f"Client F1-Score Variation - {aggregator}", fontsize=12, fontweight="bold"
    )
    ax2.grid(axis="y", alpha=0.3)

    plt.tight_layout()
    return fig


def plot_aggregator_comparison(
    results_df: pd.DataFrame, partition: int, figsize: Tuple[int, int] = (10, 6)
):
    """
    Compare aggregators side-by-side for a partition.

    Args:
        results_df: Results DataFrame
        partition: Partition ID
        figsize: Figure size
    """
    df = results_df[results_df["Partition"] == partition]

    aggregators = df["Aggregator"].unique()
    metrics = ["mIoU", "F1_Score", "Accuracy"]

    fig, ax = plt.subplots(figsize=figsize)

    agg_summary = df.groupby("Aggregator")[metrics].mean()

    x = np.arange(len(aggregators))
    width = 0.25

    for i, metric in enumerate(metrics):
        offset = (i - 1) * width
        ax.bar(x + offset, agg_summary[metric], width, label=metric, alpha=0.8)

    ax.set_xlabel("Aggregator", fontsize=11)
    ax.set_ylabel("Metric Value", fontsize=11)
    ax.set_title(
        f"Aggregator Comparison - Partition {partition}", fontsize=12, fontweight="bold"
    )
    ax.set_xticks(x)
    ax.set_xticklabels(aggregators)
    ax.legend()
    ax.grid(axis="y", alpha=0.3)

    plt.tight_layout()
    return fig


def generate_analysis_report(
    results_csv: str = "evaluation_results.csv", output_dir: str = "."
):
    """
    Generate a comprehensive analysis report with plots and statistics.

    Args:
        results_csv: Path to evaluation results CSV
        output_dir: Directory to save outputs
    """
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)

    # Load and analyze results
    analyzer = ResultsAnalyzer(results_csv)
    results_df = analyzer.results_df

    print("Generating analysis report...")
    print("\n" + "=" * 70)
    print("SUMMARY STATISTICS")
    print("=" * 70)
    print(analyzer.compute_summary_statistics())

    # Generate plots for each partition
    partitions = sorted(results_df["Partition"].unique())
    aggregators = sorted(results_df["Aggregator"].unique())

    for partition in partitions:
        print(f"\nGenerating plots for Partition {partition}...")

        # Convergence curves
        fig = plot_convergence_curves(results_df, partition)
        fig.savefig(
            output_path / f"convergence_partition_{partition}.png",
            dpi=150,
            bbox_inches="tight",
        )
        print(f"  ✓ Saved: convergence_partition_{partition}.png")
        plt.close(fig)

        # Aggregator comparison
        fig = plot_aggregator_comparison(results_df, partition)
        fig.savefig(
            output_path / f"aggregator_comparison_partition_{partition}.png",
            dpi=150,
            bbox_inches="tight",
        )
        print(f"  ✓ Saved: aggregator_comparison_partition_{partition}.png")
        plt.close(fig)

        # Client heterogeneity for each aggregator
        for aggregator in aggregators:
            fig = plot_client_heterogeneity(results_df, partition, aggregator)
            fig.savefig(
                output_path
                / f"client_heterogeneity_partition_{partition}_{aggregator}.png",
                dpi=150,
                bbox_inches="tight",
            )
            print(
                f"  ✓ Saved: client_heterogeneity_partition_{partition}_{aggregator}.png"
            )
            plt.close(fig)

    # Save detailed statistics to text file
    with open(output_path / "analysis_report.txt", "w") as f:
        f.write("=" * 70 + "\n")
        f.write("FEDERATED LEARNING EVALUATION ANALYSIS REPORT\n")
        f.write("=" * 70 + "\n\n")

        for partition in partitions:
            f.write(f"\n{'='*70}\n")
            f.write(f"PARTITION {partition}\n")
            f.write(f"{'='*70}\n")

            comparison = analyzer.compare_aggregators(partition)
            f.write(f"\nAggregator Comparison:\n{comparison}\n")

            for aggregator in aggregators:
                f.write(f"\n{'-'*70}\n")
                f.write(f"Aggregator: {aggregator}\n")
                f.write(f"{'-'*70}\n")

                trends = analyzer.get_convergence_trends(partition, aggregator)
                f.write(f"\nConvergence Trends:\n{trends}\n")

    print(f"\n✓ Analysis report saved to {output_path / 'analysis_report.txt'}")
    print("\n" + "=" * 70)
    print("Report generation complete!")
    print("=" * 70)


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        results_csv = sys.argv[1]
    else:
        results_csv = "evaluation_results.csv"

    if len(sys.argv) > 2:
        output_dir = sys.argv[2]
    else:
        output_dir = "./analysis_report"

    if Path(results_csv).exists():
        generate_analysis_report(results_csv, output_dir)
    else:
        print(f"Error: {results_csv} not found!")
        print("Usage: python analysis_utils.py <results_csv> [output_dir]")
